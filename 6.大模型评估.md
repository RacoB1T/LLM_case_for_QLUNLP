# å…­ã€å¤§æ¨¡å‹è¯„ä¼°

---

æ¨¡å‹è¯„ä¼°ï¼Œæ—¨åœ¨è¯„ä¼°æ¨¡å‹åœ¨æœªæ›¾æ¥è§¦è¿‡çš„æ•°æ®ä¸Šçš„æ³›åŒ–èƒ½åŠ›åŠé¢„æµ‹ç²¾ç¡®åº¦ï¼Œä»¥æ­¤æ›´å¥½åœ°ç†è§£æ¨¡å‹åœ¨å®é™…åº”ç”¨åœºæ™¯ä¸­çš„è¡¨ç°ã€‚è¿™æ˜¯æ¨¡å‹å¼€å‘å®Œæˆåä¸å¯æˆ–ç¼ºçš„ä¸€ä¸ªç¯èŠ‚ã€‚å¯¹äºä¸“æ³¨äºå•ä¸€ä»»åŠ¡çš„è‡ªç„¶è¯­è¨€å¤„ç†ç®—æ³•è€Œè¨€ï¼Œé€šå¸¸éœ€è¦åˆ›å»ºä¸€ä¸ªç‹¬ç«‹äºè®­ç»ƒæ•°æ®çš„è¯„ä¼°æ•°æ®é›†ï¼Œå¹¶é€‰ç”¨é€‚å½“çš„è¯„ä¼°æŒ‡æ ‡æ¥é¢„æµ‹æ¨¡å‹åœ¨ç°å®ä¸–ç•Œä¸­çš„æ•ˆèƒ½ã€‚ç„¶è€Œï¼Œç”±äºæˆ‘ä»¬æ— æ³•å®Œå…¨æŒæ¡æ•°æ®çš„çœŸå®åˆ†å¸ƒæƒ…å†µï¼Œå•çº¯ä¾èµ–ä¸è®­ç»ƒæ•°æ®ç‹¬ç«‹ä¸”ç›¸åŒåˆ†å¸ƒçš„æ–¹æ³•æ„å»ºçš„è¯„ä¼°æ•°æ®é›†ï¼Œåœ¨è®¸å¤šæƒ…å½¢ä¸‹å¯èƒ½æ— æ³•å…¨é¢å‡†ç¡®åœ°åæ˜ æ¨¡å‹çš„å®é™…çŠ¶å†µã€‚ä¾‹å¦‚ï¼Œå³ä½¿é¢å¯¹åŒæ ·çš„è®­ç»ƒæ•°æ®ï¼Œé‡‡ç”¨ä¸åŒç®—æ³•æˆ–è¶…å‚æ•°é…ç½®æ‰€è®­ç»ƒå‡ºçš„å››ä¸ªåˆ†ç±»å™¨ï¼Œè‹¥æœªèƒ½è·å–åˆ°æ•°æ®çš„çœŸå®åˆ†å¸ƒæˆ–æµ‹è¯•æ•°æ®é‡‡æ ·ä¸è¶³ï¼Œé‚£ä¹ˆè¿™äº›åˆ†ç±»å™¨åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°å°±éš¾ä»¥é€šè¿‡å‰è¿°è¯„ä¼°æ‰‹æ®µå¾—å‡ºçš„ç»“æœå‡†ç¡®é¢„æµ‹ã€‚

åœ¨æ¨¡å‹è¯„ä¼°è¿‡ç¨‹ä¸­ï¼Œé€šå¸¸ä¼šä½¿ç”¨ä¸€ç³»åˆ—è¯„ä¼°æŒ‡æ ‡ï¼ˆEvaluation Metricsï¼‰æ¥è¡¡é‡æ¨¡å‹çš„è¡¨ç°ï¼Œå¦‚ï¼šå‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1 åˆ†æ•°ã€ROC æ›²çº¿å’Œ AUC ç­‰ã€‚è¿™äº›æŒ‡æ ‡æ ¹æ®å…·ä½“çš„ä»»åŠ¡å’Œåº”ç”¨åœºæ™¯å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚æ–‡æœ¬ç”Ÿæˆä»»åŠ¡çš„è¯„ä¼°é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜æºè‡ªè¯­è¨€æœ¬èº«çš„çµæ´»æ€§å’Œå¤šæ ·æ€§ï¼ŒåŒä¸€å¥è¯å¯ä»¥é€šè¿‡å¤šç§æ–¹å¼è¡¨è¾¾ã€‚è¿™ç§å¤šæ ·æ€§ä½¿å¾—æ–‡æœ¬ç”Ÿæˆä»»åŠ¡çš„è¯„ä¼°å˜å¾—å¤æ‚ï¼Œå› ä¸ºå³ä½¿æ˜¯è¯­ä¹‰ç›¸åŒä½†ç”¨è¯å·®å¼‚è¾ƒå¤§çš„å¥å­ï¼Œä¹Ÿå¯èƒ½è¢«é”™è¯¯åœ°è§†ä¸ºä¸æ­£ç¡®æˆ–ä½è´¨é‡çš„è¾“å‡ºã€‚

åˆç†é€‰æ‹©è¯„ä¼°æ•°æ®é›†å¯¹äºæ¨¡å‹è¯„ä¼°è‡³å…³é‡è¦ã€‚å¯¹äºå•ä¸€ä»»åŠ¡çš„è¯„ä¼°ï¼Œé€šå¸¸çš„åšæ³•æ˜¯å°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ä¸‰éƒ¨åˆ†ã€‚è®­ç»ƒé›†ç”¨äºæ¨¡å‹è®­ç»ƒï¼ŒéªŒè¯é›†ç”¨äºæ¨¡å‹è¶…å‚æ•°è°ƒæ•´å’Œæ¨¡å‹é€‰æ‹©ï¼Œè€Œæµ‹è¯•é›†åˆ™ç”¨æ¥æœ€ç»ˆè¯„ä¼°æ¨¡å‹çš„è¡¨ç°ã€‚ä¸ºäº†é˜²æ­¢æ•°æ®æ³„éœ²ï¼Œè¯„ä¼°æ•°æ®é›†åº”å½“ä¸è®­ç»ƒæ•°æ®é›†ä¿æŒç‹¬ç«‹ã€‚åŒæ—¶ï¼Œè¯„ä¼°æ•°æ®é›†éœ€è¦å…·å¤‡ä»£è¡¨æ€§ï¼Œèƒ½å¤Ÿåæ˜ æ¨¡å‹å®é™…åº”ç”¨ä¸­å¯èƒ½é‡åˆ°çš„å„ç§æ•°æ®æƒ…å†µï¼ŒåŒ…æ‹¬å¸¸è§çš„ã€ç‰¹æ®Šçš„ä»¥åŠè¾¹ç¼˜æ¡ˆä¾‹ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨å¹¿æ³›çš„æ¡ä»¶ä¸‹éƒ½èƒ½è¡¨ç°å‡ºè‰²ã€‚æ­¤å¤–ï¼Œè¯„ä¼°æ•°æ®é›†çš„è§„æ¨¡ä¹Ÿåº”è¶³å¤Ÿå¤§ï¼Œä»¥ä¾¿å…¨é¢æ£€éªŒæ¨¡å‹çš„æ€§èƒ½ã€‚

å¯¹äºå¤§è¯­è¨€æ¨¡å‹çš„è¯„ä¼°ï¼Œä¸ä»…æ¶‰åŠæ•°æ®é›†çš„é€‰æ‹©é—®é¢˜ï¼Œè¿˜é¢ä¸´ç€æ„é€ è¯„æµ‹æ•°æ®é›†çš„æŒ‘æˆ˜ï¼Œå› ä¸ºè¿™ç±»æ¨¡å‹èƒ½å¤Ÿåœ¨å•ä¸€æ¡†æ¶å†…å®Œæˆè‡ªç„¶è¯­è¨€ç†è§£ã€é€»è¾‘æ¨ç†ã€è‡ªç„¶è¯­è¨€ç”ŸæˆåŠå¤šè¯­è¨€å¤„ç†ç­‰å¤šé¡¹ä»»åŠ¡ã€‚å› æ­¤ï¼Œæ„å»ºæ—¢èƒ½æ¶µç›–å„ä¸ªä»»åŠ¡åˆèƒ½åæ˜ æ¨¡å‹ç»¼åˆèƒ½åŠ›çš„è¯„æµ‹æ•°æ®é›†æ˜¯ä¸€é¡¹é‡è¦çš„ç ”ç©¶è¯¾é¢˜ã€‚å¦å¤–ï¼Œé‰´äºå¤§è¯­è¨€æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹åŒ…å«è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒã€æœ‰ç›‘ç£å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ ç­‰å¤šä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µçš„ç›®æ ‡å„ä¸ç›¸åŒï¼Œæ‰€ä»¥å¯¹ä¸åŒé˜¶æ®µçš„æ¨¡å‹ä¹Ÿéœ€è¦é‡‡ç”¨ä¸åŒçš„è¯„ä¼°æ ‡å‡†å’Œæ–¹æ³•ï¼Œç¡®ä¿æ¯ä¸ªé˜¶æ®µçš„å‘å±•æ–¹å‘ç¬¦åˆé¢„æœŸã€‚æ€»ä¹‹ï¼Œæ— è®ºæ˜¯å°è§„æ¨¡è¿˜æ˜¯å¤§è§„æ¨¡çš„è¯­è¨€æ¨¡å‹ï¼Œæœ‰æ•ˆçš„è¯„ä¼°éƒ½æ˜¯ç¡®ä¿æ¨¡å‹è´¨é‡å’Œå®ç”¨æ€§çš„é‡è¦ç¯èŠ‚ã€‚

æˆ‘ä»¬é€šå¸¸ä»ä»¥ä¸‹å‡ ä¸ªç»´åº¦æ¥ç»¼åˆè¯„ä¼°LLMçš„èƒ½åŠ›ï¼š

*   è¯­ä¹‰ç†è§£ï¼ˆUnderstandingï¼‰
*   çŸ¥è¯†æ¨ç†ï¼ˆReasoningï¼‰
*   ä¸“ä¸šèƒ½åŠ›ï¼ˆe.g. codingã€mathï¼‰
*   åº”ç”¨èƒ½åŠ›ï¼ˆMedicalAppsã€AgentAppsã€AI-FOR-SCI ...ï¼‰
*   æŒ‡ä»¤è·Ÿéšï¼ˆInstruction Followingï¼‰
*   é²æ£’æ€§ï¼ˆRobustnessï¼‰
*   åè§ï¼ˆBiasï¼‰
*   å¹»è§‰ï¼ˆHallucinationsï¼‰
*   å®‰å…¨æ€§ï¼ˆSafetyï¼‰

ç›®å‰è¯„æµ‹æ–¹æ³•å¯ä»¥åˆ†ä¸ºäººå·¥è¯„æµ‹å’Œè‡ªåŠ¨è¯„æµ‹ï¼Œå…¶ä¸­ï¼Œè‡ªåŠ¨è¯„æµ‹æŠ€æœ¯ç›¸æ¯”äººå·¥è¯„æµ‹æ¥è®²ï¼Œå…·æœ‰æ•ˆç‡é«˜ã€ä¸€è‡´æ€§å¥½ã€å¯å¤ç°ã€é²æ£’æ€§å¥½ç­‰ç‰¹ç‚¹ï¼Œé€æ¸æˆä¸ºä¸šç•Œç ”ç©¶çš„é‡ç‚¹ã€‚æ¨¡å‹çš„è‡ªåŠ¨è¯„æµ‹æŠ€æœ¯å¯ä»¥åˆ†ä¸ºRule-basedå’ŒModel-basedä¸¤å¤§ç±»ï¼š

*   Rule-basedæ–¹æ³•ï¼š
    *   benchmarkä»¥å®¢è§‚é¢˜ä¸ºä¸»ï¼Œä¾‹å¦‚å¤šé€‰é¢˜ï¼Œè¢«æµ‹çš„LLMé€šè¿‡ç†è§£context/questionï¼Œæ¥æŒ‡å®šæœ€ä½³ç­”æ¡ˆã€‚
    *   è§£æLLMçš„responseï¼Œä¸æ ‡å‡†ç­”æ¡ˆåšå¯¹æ¯”ã€‚
    *   è®¡ç®—metricï¼ˆaccuracyã€rougeã€bleuç­‰ï¼‰ã€‚
*   Model-basedæ–¹æ³•ï¼š
    *   è£åˆ¤å‘˜æ¨¡å‹ï¼ˆe.g. GPT-4ã€Claudeã€Expert Models/Reward modelsï¼‰ã€‚
    *   LLM Peer-examinationã€‚

## å¸å—ï¼ˆOpenCompassï¼‰

OpenCompass æ˜¯é¢å‘å¤§æ¨¡å‹è¯„æµ‹çš„ä¸€ç«™å¼å¹³å°ã€‚å…¶ä¸»è¦ç‰¹ç‚¹å¦‚ä¸‹ï¼š

- **å¼€æºå¯å¤ç°**ï¼šæä¾›å…¬å¹³ã€å…¬å¼€ã€å¯å¤ç°çš„å¤§æ¨¡å‹è¯„æµ‹æ–¹æ¡ˆ
- **å…¨é¢çš„èƒ½åŠ›ç»´åº¦**ï¼šäº”å¤§ç»´åº¦è®¾è®¡ï¼Œæä¾› 70+ ä¸ªæ•°æ®é›†çº¦ 40 ä¸‡é¢˜çš„çš„æ¨¡å‹è¯„æµ‹æ–¹æ¡ˆï¼Œå…¨é¢è¯„ä¼°æ¨¡å‹èƒ½åŠ›
- **ä¸°å¯Œçš„æ¨¡å‹æ”¯æŒ**ï¼šå·²æ”¯æŒ 20+ HuggingFace åŠ API æ¨¡å‹
- **åˆ†å¸ƒå¼é«˜æ•ˆè¯„æµ‹**ï¼šä¸€è¡Œå‘½ä»¤å®ç°ä»»åŠ¡åˆ†å‰²å’Œåˆ†å¸ƒå¼è¯„æµ‹ï¼Œæ•°å°æ—¶å³å¯å®Œæˆåƒäº¿æ¨¡å‹å…¨é‡è¯„æµ‹
- **å¤šæ ·åŒ–è¯„æµ‹èŒƒå¼**ï¼šæ”¯æŒé›¶æ ·æœ¬ã€å°æ ·æœ¬åŠæ€ç»´é“¾è¯„æµ‹ï¼Œç»“åˆæ ‡å‡†å‹æˆ–å¯¹è¯å‹æç¤ºè¯æ¨¡æ¿ï¼Œè½»æ¾æ¿€å‘å„ç§æ¨¡å‹æœ€å¤§æ€§èƒ½
- **çµæ´»åŒ–æ‹“å±•**ï¼šæƒ³å¢åŠ æ–°æ¨¡å‹æˆ–æ•°æ®é›†ï¼Ÿæƒ³è¦è‡ªå®šä¹‰æ›´é«˜çº§çš„ä»»åŠ¡åˆ†å‰²ç­–ç•¥ï¼Œç”šè‡³æ¥å…¥æ–°çš„é›†ç¾¤ç®¡ç†ç³»ç»Ÿï¼ŸOpenCompass çš„ä¸€åˆ‡å‡å¯è½»æ¾æ‰©å±•ï¼

### 4.1.1 å®‰è£…

pip å®‰è£…

```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate Qwen
# æ”¯æŒç»å¤§å¤šæ•°æ•°æ®é›†åŠæ¨¡å‹
pip install -U opencompass

# å®Œæ•´å®‰è£…ï¼ˆæ”¯æŒæ›´å¤šæ•°æ®é›†ï¼‰
# pip install "opencompass[full]"

# API æµ‹è¯•ï¼ˆä¾‹å¦‚ OpenAIã€Qwenï¼‰
# pip install "opencompass[api]"
```

æºç æ„å»º

```shell
# è¿”å›LLMç›®å½•
cd ~/LLM
# æ¿€æ´»ç¯å¢ƒ
conda activate Qwen
# ä¸‹è½½æºç 
git clone https://github.com/open-compass/opencompass opencompass
cd opencompass
# å®‰è£…
pip install -e .
```

### é¦–æ¬¡æµ‹è¯•

OpenCompass æ”¯æŒé€šè¿‡å‘½ä»¤è¡Œç•Œé¢ (CLI) æˆ– Python è„šæœ¬æ¥è®¾ç½®é…ç½®ã€‚å¯¹äºç®€å•çš„è¯„ä¼°è®¾ç½®ï¼Œæˆ‘ä»¬æ¨èä½¿ç”¨ CLIï¼›è€Œå¯¹äºæ›´å¤æ‚çš„è¯„ä¼°ï¼Œåˆ™å»ºè®®ä½¿ç”¨è„šæœ¬æ–¹å¼ã€‚ä½ å¯ä»¥åœ¨examplesæ–‡ä»¶å¤¹ä¸‹æ‰¾åˆ°æ›´å¤šè„šæœ¬ç¤ºä¾‹ã€‚

```bash
# CLI
opencompass --models hf_internlm2_5_1_8b_chat --datasets demo_gsm8k_chat_gen
# Python è„šæœ¬
opencompass examples/eval_chat_demo.py
```

| dataset    | version | metric   | mode | internlm2_5-1_8b-chat-hf |
| ---------- | ------- | -------- | ---- | ------------------------ |
| demo_gsm8k | 1d7fe4  | accuracy | gen  | 50.00                    |

### å®¢è§‚è¯„ä¼°

é€šè¿‡ä¸‹è¿°å‘½ä»¤ï¼Œä¸‹è½½è¯„æµ‹æ•°æ®é›†å¹¶åˆ›å»ºè¯„æµ‹è„šæœ¬ã€‚

```shell
# ä¸‹è½½æ•°æ®é›†å¹¶è½¬æ¢æˆæŒ‡å®šæ ¼å¼
cd ~/LLM/data
mkdir raw
cd raw

git clone "https://github.com/FreedomIntelligence/CMB.git"
cd CMB
unzip "./data/CMB.zip" -d "./data/" 
rm "./data/CMB.zip"

cd ~/LLM/data
cp raw/CMB/CMB-Exam/CMB-test/CMB-test-choice-question-merge.json ./CMB/test.json
cp raw/CMB/CMB-Exam/CMB-val/CMB-val-merge.json ./CMB/val.json

# ä½¿ç”¨OpenCompassè¯„æµ‹
# ç¼–å†™è„šæœ¬ eval_cmb.sh
cd ~/LLM
vim script/eval_cmb.sh

```

è¯„æµ‹è„šæœ¬`eval_cmb.sh`å†…å®¹å¦‚ä¸‹ï¼š

```shell
CUDA_VISIBLE_DEVICES=0 \
python ./opencompass/run.py \
--datasets cmb_gen \
--hf-type chat \
--hf-path /mnt/suke/LLM/model/Qwen2.5-1.5B-Instruct \
--max-out-len 1024 \
--generation-kwargs "do_sample=True temperature=0.3" \
--hf-num-gpus 1 \
--work-dir ./evaluation/dpo \
--debug
```

å‚æ•°è§£æï¼š

*   `python ./opencompass/run.py`ï¼šè°ƒç”¨ Python è§£é‡Šå™¨æ¥è¿è¡Œ `./opencompass/run.py` è„šæœ¬ã€‚
*   `--datasets`ï¼šè¿™ä¸ªå‚æ•°ç”¨äºå®šä¹‰è¿è¡Œä»»åŠ¡ä¸­åŠ è½½å’Œä½¿ç”¨çš„å…·ä½“æ•°æ®é›†ã€‚`cmb_gen` è¡¨ç¤ºåœ¨`cmb`æ•°æ®é›†ä¸Šçš„ç”Ÿæˆå¼è¯„æµ‹è¿˜æœ‰`ppl`å³åˆ¤åˆ«å¼è¯„æµ‹ã€‚
*   `--hf-type`ï¼š `HuggingFace`æ¨¡å‹ç±»å‹ï¼Œå¯é€‰å€¼ä¸º `chat `æˆ– `base`ã€‚
*   `--hf-path`ï¼š `HuggingFace`æ¨¡å‹è·¯å¾„ã€‚
*   `--max-out-len`ï¼šç”Ÿæˆçš„æœ€å¤§`token`æ•°ï¼Œå³ç”Ÿæˆçš„æ–‡æœ¬ä¸èƒ½è¶…è¿‡è¿™ä¸ªé•¿åº¦é™åˆ¶ã€‚
*   `--generation-kwargs`ï¼šç”¨äºæŒ‡å®šç”Ÿæˆå‚æ•°çš„é™„åŠ é€‰é¡¹ã€‚`do_sample=True` è¡¨ç¤ºå¯ç”¨é‡‡æ ·æ¨¡å¼è€Œä¸æ˜¯è´ªå¿ƒæœç´¢ï¼Œ`temperature=0.3` ç”¨äºæ§åˆ¶ç”Ÿæˆæ—¶çš„éšæœºæ€§ï¼Œå€¼è¶Šä½è¡¨ç¤ºè¾“å‡ºæ›´ç¡®å®šï¼Œè¶Šé«˜è¡¨ç¤ºè¾“å‡ºæ›´å¤šæ ·åŒ–ã€‚ã€‚
*   `--hf-num-gpus`ï¼šæŒ‡å®šç”¨äºè¿è¡Œæ¨¡å‹çš„ GPU çš„æ•°é‡ã€‚
*   `--work-dir`ï¼šä¿å­˜è¯„ä¼°æ—¥å¿—å’Œç»“æœçš„å·¥ä½œç›®å½•ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®éªŒç»“æœå°†ä¿å­˜åˆ° `./evaluation/dpo/{TIMESTAMP}`ã€‚

æ¥ä¸‹æ¥ï¼Œé€šè¿‡ä¸‹è¿°å‘½ä»¤è¿›è¡Œè¯„æµ‹ï¼š

```shell
bash script/eval_cmb.sh
```

å®Œæˆè¯„æµ‹åä¼šæ˜¾ç¤ºè¯„æµ‹ç»“æœå¦‚ä¸‹ï¼š

```shell
| dataset | version | metric | mode | checkpoint-233-merged_hf |
|----- | ----- | ----- | ----- | -----|
| cmb | fb9826 | accuracy | gen | 53.21 |
| cmb_test | fb9826 | accuracy | gen | 0.00 |

```

ç”±äºå¸å—æ¡†æ¶å’Œæ•°æ®é›†çš„åŸå› ï¼Œä¸Šè¿°è¾“å‡ºä¸­ï¼Œæµ‹è¯•é›†å¹¶æ²¡æœ‰è¢«è·‘å‡ºæ¥ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦ä½¿ç”¨è‡ªå·±ç¼–å†™çš„ä»£ç è¿›è¡Œè¯„ä¼°ã€‚

```shell
# è¿”å›LLMç›®å½•
cd ~/LLM
# ç¼–å†™è¯„ä¼°ä»£ç 
vim src/cmb_test_acc.py
# ä¸‹è½½å¸¦ç­”æ¡ˆçš„testæ•°æ® CMB-test-choice-answer.json
```

`cmb_test_acc.py`ä»£ç å¦‚ä¸‹ï¼š

```python
import json
import re
predict_file = open('/mnt/suke/LLM/evaluation/dpo/20250609_014355/predictions/Qwen2.5-1.5B-Instruct_hf/cmb_test.json', 'r', encoding='utf-8')
answer_file = open('/mnt/suke/LLM/data/CMB/CMB-test-choice-answer.json','r', encoding='utf8')
predict_json = json.load(predict_file)
answer_json = json.load(answer_file)
answers = []
for json_obj in answer_json:
    answers.append(json_obj['answer'])
predictions = []
def extract_options(text):
    # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…åªåŒ…å«å­—æ¯Aåˆ°Gçš„é€‰é¡¹
    pattern = re.compile(r'[A-F]+')
    options = pattern.findall(text)
    # ä½¿ç”¨é›†åˆå»é™¤é‡å¤çš„é€‰é¡¹
    unique_options = set(options)
    # å°†é›†åˆè½¬æ¢ä¸ºåˆ—è¡¨ï¼Œå¹¶è½¬æ¢ä¸ºå¤§å†™
    unique_options = sorted([opt for opt in unique_options])
    return unique_options
for key in predict_json.keys():
    prediction = predict_json[key]['prediction']
    prediction = extract_options(prediction)
    prediction = ''.join(prediction)
    predictions.append(prediction)
# upload_file = open('q2_pred.json', 'w', encoding='utf-8')
upload_objs = []
total_acc = 0
for idx, pred in enumerate(predictions):
    upload_objs.append({'id': idx+1, 'model_answer': pred})
    if answers[idx] == pred:
        total_acc += 1
print(f"acc: {total_acc / len(predictions)}")
# json.dump(upload_objs, upload_file, ensure_ascii=False, indent=4)
# upload_file.close()
predict_file.close()
answer_file.close()
```

åœ¨æµ‹è¯•é›†ä¸Šè¿è¡Œè¯„æµ‹ï¼š

```shell
python src/cmb_test_acc.py

# acc: 0.59
```

## EvalScope

â€œEvalScopeâ€æ˜¯é­”æ­ç¤¾åŒºå€¾åŠ›æ‰“é€ çš„æ¨¡å‹è¯„æµ‹ä¸æ€§èƒ½åŸºå‡†æµ‹è¯•æ¡†æ¶ï¼Œä¸ºæ‚¨çš„æ¨¡å‹è¯„ä¼°éœ€æ±‚æä¾›ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆã€‚æ— è®ºæ‚¨åœ¨å¼€å‘ä»€ä¹ˆç±»å‹çš„æ¨¡å‹ï¼ŒEvalScope éƒ½èƒ½æ»¡è¶³æ‚¨çš„éœ€æ±‚ï¼š

- ğŸ§  å¤§è¯­è¨€æ¨¡å‹
- ğŸ¨ å¤šæ¨¡æ€æ¨¡å‹
- ğŸ” Embedding æ¨¡å‹
- ğŸ† Reranker æ¨¡å‹
- ğŸ–¼ï¸ CLIP æ¨¡å‹
- ğŸ­ AIGCæ¨¡å‹ï¼ˆå›¾ç”Ÿæ–‡/è§†é¢‘ï¼‰

EvalScope ä¸ä»…ä»…æ˜¯ä¸€ä¸ªè¯„æµ‹å·¥å…·ï¼Œå®ƒæ˜¯æ‚¨æ¨¡å‹ä¼˜åŒ–ä¹‹æ—…çš„å¾—åŠ›åŠ©æ‰‹ï¼š

- ğŸ… å†…ç½®å¤šä¸ªä¸šç•Œè®¤å¯çš„æµ‹è¯•åŸºå‡†å’Œè¯„æµ‹æŒ‡æ ‡ï¼šMMLUã€CMMLUã€C-Evalã€GSM8K ç­‰ã€‚
- ğŸ“Š æ¨¡å‹æ¨ç†æ€§èƒ½å‹æµ‹ï¼šç¡®ä¿æ‚¨çš„æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­è¡¨ç°å‡ºè‰²ã€‚
- ğŸš€ ä¸ [ms-swift](https://github.com/modelscope/ms-swift) è®­ç»ƒæ¡†æ¶æ— ç¼é›†æˆï¼Œä¸€é”®å‘èµ·è¯„æµ‹ï¼Œä¸ºæ‚¨çš„æ¨¡å‹å¼€å‘æä¾›ä»è®­ç»ƒåˆ°è¯„ä¼°çš„å…¨é“¾è·¯æ”¯æŒã€‚

![](pic/1.png)

### å®‰è£…

#### æ–¹å¼1. ä½¿ç”¨pipå®‰è£…

1.åˆ›å»ºcondaç¯å¢ƒ (å¯é€‰)

```
# å»ºè®®ä½¿ç”¨ python 3.10
conda create -n evalscope python=3.10

# æ¿€æ´»condaç¯å¢ƒ
conda activate evalscope
```

2.pipå®‰è£…ä¾èµ–

```shell
pip install evalscope                # å®‰è£… Native backend (é»˜è®¤)
# é¢å¤–é€‰é¡¹
pip install 'evalscope[opencompass]'   # å®‰è£… OpenCompass backend
pip install 'evalscope[vlmeval]'       # å®‰è£… VLMEvalKit backend
pip install 'evalscope[rag]'           # å®‰è£… RAGEval backend
pip install 'evalscope[perf]'          # å®‰è£… æ¨¡å‹å‹æµ‹æ¨¡å— ä¾èµ–
pip install 'evalscope[app]'           # å®‰è£… å¯è§†åŒ– ç›¸å…³ä¾èµ–
pip install 'evalscope[all]'           # å®‰è£…æ‰€æœ‰ backends (Native, OpenCompass, VLMEvalKit, RAGEval)
```

#### æ–¹å¼2. ä½¿ç”¨æºç å®‰è£…

ä½¿ç”¨æºç å®‰è£…å¯ä½¿ç”¨æœ€æ–°åŠŸèƒ½

1.ä¸‹è½½æºç 

```shell
git clone https://github.com/modelscope/evalscope.git
```

2.å®‰è£…ä¾èµ–

```shell
cd evalscope/

pip install -e .                  # å®‰è£… Native backend
# é¢å¤–é€‰é¡¹
pip install -e '.[opencompass]'   # å®‰è£… OpenCompass backend
pip install -e '.[vlmeval]'       # å®‰è£… VLMEvalKit backend
pip install -e '.[rag]'           # å®‰è£… RAGEval backend
pip install -e '.[perf]'          # å®‰è£… æ¨¡å‹å‹æµ‹æ¨¡å— ä¾èµ–
pip install -e '.[app]'           # å®‰è£… å¯è§†åŒ– ç›¸å…³ä¾èµ–
pip install -e '.[all]'           # å®‰è£…æ‰€æœ‰ backends (Native, OpenCompass, VLMEvalKit, RAGEval)
```

### ç®€å•æµ‹è¯„

#### 1.å‘½ä»¤è¡Œæµ‹è¯•

åœ¨ä»»æ„è·¯å¾„ä¸‹æ‰§è¡Œ`eval`å‘½ä»¤ï¼š

```shell
evalscope eval \
 --model Qwen/Qwen2.5-0.5B-Instruct \
 --datasets gsm8k arc \
 --limit 5
```

**ç»“æœå¦‚ä¸‹ï¼š**

| Model                  	      | Dataset | Metric                     | Subset                | Num   | Score  | Cat.0     |
+=========================+=========+==================+================+=======+
| Qwen2.5-0.5B-Instruct   | arc         | AverageAccuracy  | ARC-Easy            |   5        |  0.6     | default  |
| Qwen2.5-0.5B-Instruct   | arc         | AverageAccuracy  | ARC-Challenge   |   5       |  0.4     | default  |
| Qwen2.5-0.5B-Instruct   | gsm8k   | AverageAccuracy  | main                    |   5       |  0.6     | default  |

#### 2.pyä»£ç æµ‹è¯•

ä½¿ç”¨pythonä»£ç è¿›è¡Œè¯„æµ‹æ—¶éœ€è¦ç”¨`run_task`å‡½æ•°æäº¤è¯„æµ‹ä»»åŠ¡ï¼Œä¼ å…¥ä¸€ä¸ª`TaskConfig`ä½œä¸ºå‚æ•°ï¼š

```python
from evalscope.run import run_task

task_cfg = {
    'model': 'Qwen/Qwen2.5-0.5B-Instruct',
    'datasets': ['gsm8k', 'arc'],
    'limit': 5
}

run_task(task_cfg=task_cfg)
```

`--model`: æŒ‡å®šäº†æ¨¡å‹åœ¨[ModelScope](https://modelscope.cn/)ä¸­çš„`model_id`ï¼Œå¯è‡ªåŠ¨ä¸‹è½½ï¼Œä¾‹å¦‚[Qwen/Qwen2.5-0.5B-Instruct](https://modelscope.cn/models/Qwen/Qwen2.5-0.5B-Instruct/summary)

ï¼›ä¹Ÿå¯ä½¿ç”¨æ¨¡å‹çš„æœ¬åœ°è·¯å¾„ï¼Œä¾‹å¦‚`/path/to/model`

`--datasets`: æ•°æ®é›†åç§°ï¼Œæ”¯æŒè¾“å…¥å¤šä¸ªæ•°æ®é›†ï¼Œä½¿ç”¨ç©ºæ ¼åˆ†å¼€ï¼Œæ•°æ®é›†å°†è‡ªåŠ¨ä»modelscopeä¸‹è½½ï¼Œæ”¯æŒçš„æ•°æ®é›†å‚è€ƒ[æ•°æ®é›†åˆ—è¡¨](https://evalscope.readthedocs.io/zh-cn/latest/get_started/supported_dataset.html#id1)

`--limit`: æ¯ä¸ªæ•°æ®é›†æœ€å¤§è¯„æµ‹æ•°æ®é‡ï¼Œä¸å¡«å†™åˆ™é»˜è®¤ä¸ºå…¨éƒ¨è¯„æµ‹ï¼Œå¯ç”¨äºå¿«é€ŸéªŒè¯

**ç»“æœä¸ä¸Šè¿°ç›¸åŒä¸å†èµ˜è¿°ã€‚**

### å¤æ‚æµ‹è¯„

è‹¥æƒ³è¿›è¡Œæ›´åŠ è‡ªå®šä¹‰çš„è¯„æµ‹ï¼Œä¾‹å¦‚è‡ªå®šä¹‰æ¨¡å‹å‚æ•°ï¼Œæˆ–è€…æ•°æ®é›†å‚æ•°ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼Œå¯åŠ¨è¯„æµ‹æ–¹å¼ä¸ç®€å•è¯„æµ‹ä¸€è‡´ï¼Œä¸‹é¢å±•ç¤ºäº†ä½¿ç”¨`eval`å‘½ä»¤å¯åŠ¨è¯„æµ‹ï¼š

```bash
evalscope eval \
 --model Qwen/Qwen3-0.6B \
 --model-args '{"revision": "master", "precision": "torch.float16", "device_map": "auto"}' \
 --generation-config '{"do_sample":true,"temperature":0.6,"max_new_tokens":512,"chat_template_kwargs":{"enable_thinking": false}}' \
 --dataset-args '{"gsm8k": {"few_shot_num": 0, "few_shot_random": false}}' \
 --datasets gsm8k \
 --limit 10
```

```
+------------+-----------+-----------------+----------+-------+---------+---------+
| Model      | Dataset   | Metric          | Subset   |   Num |   Score | Cat.0   |
+============+===========+=================+==========+=======+=========+=========+
| Qwen3-0.6B | gsm8k     | AverageAccuracy | main     |    10 |     0.3 | default |
+------------+-----------+-----------------+----------+-------+---------+---------+ 
```

### ä½¿ç”¨è£åˆ¤æ¨¡å‹ä¸»è§‚è¯„ä»·

åœ¨è¯„æµ‹æ—¶ï¼Œå¯ä»¥ä½¿ç”¨è£åˆ¤æ¨¡å‹å¯¹æ¨¡å‹çš„è¾“å‡ºè¿›è¡Œè¯„ä¼°ï¼Œæ­¤å¤–æœ‰äº›æ•°æ®é›†éœ€è¦ä½¿ç”¨è£åˆ¤æ¨¡å‹è¿›è¡Œè¯„æµ‹ï¼Œä¾‹å¦‚`simple_qa`æ•°æ®é›†ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨è¯„æµ‹ï¼š

```python
from evalscope import TaskConfig, run_task
from evalscope.constants import EvalType, JudgeStrategy

task_cfg = TaskConfig(
    model='qwen2.5-7b-instruct',
    api_url='https://dashscope.aliyuncs.com/compatible-mode/v1',
    api_key= 'dashscope api-key',
    eval_type=EvalType.SERVICE,
    datasets=[
        # 'simple_qa',
        'chinese_simpleqa',
    ],
    eval_batch_size=5,
    limit=5,
    judge_strategy=JudgeStrategy.AUTO,
    judge_model_args={
        'model_id': 'qwen2.5-72b-instruct',
        'api_url': 'https://dashscope.aliyuncs.com/compatible-mode/v1',
        'api_key': 'dashscope api-key',
    }
)

run_task(task_cfg=task_cfg)
```

ç»“æœï¼š

![image-20250612162902301](pic/2.png)

---

![](QLUNLP_logo.png)