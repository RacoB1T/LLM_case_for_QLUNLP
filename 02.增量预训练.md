# **二、增量预训练**

---

本文将介绍如何对Qwen2.5-1.5B模型进行增量预训练

注：对于预训练的模型应该用base模型，而不是已经训练好的Instruct对话模型

## 1.1 数据准备

### **1.1.1 增量预训练数据集**

- 数据格式

  ```json
  {"response": "11111"}
  {"response": "aaaaa"}
  {"response": "AAAAA"}
  ```

- 数据说明

  medical_book_zh.json ：共8475条，来自医疗教材的文本数据。

- 数据样例

  ```json
  数据样例
  {"text": "预后判断方面也具有重要价值。肌钙蛋白(troponin)（包括肌钙蛋白T和肌钙蛋白I)是心肌梗死诊断危险分层病情预测和预后评估的首选指标。"}
  ```
  
- 下载地址： https://huggingface.co/datasets/shibing624/medical/tree/main/pretrain 

**1.1.2 有监督微调数据集**

- 数据格式

  ```json
  {"query": "11111", "response": "22222"}
  {"query": "aaaaa", "response": "bbbbb"}
  {"query": "AAAAA", "response": "BBBBB"}
  ```

- 数据说明

  `QiZhen_sft_20k` ：包含20k训练数据（该数据集来自于启真医学知识库收集整理的真实医患知识问答数据以及在启真医学知识库的药品文本知识基础上，通过对半结构化数据设置特定的问题模板构造的指令数据）。

- 数据样例

  ```json
      {
          "instruction": "广誉远安宫牛黄丸的四大优势？",
          "input": "",
          "output": "1、天然牛黄，品质最优\n\n广誉远推出的安宫牛黄丸精选58W元/公斤的天然牛黄，胆红素含量高达30-50%。\n\n市场上的安宫牛黄丸所用牛黄有人工牛黄、体外培育牛黄和天然牛黄，天然牛黄价格最高，堪比黄金，疗效最佳。国家规定，急救用药必须使用天然牛黄，所以，家庭必备必须是含有天然牛黄的安宫牛黄丸。\n\nl即使是天然牛黄，也分品质好坏，国家规定天然牛黄的胆红素含量不能低于25%，广誉远的安宫牛黄丸胆红素含量高于国家标准达到30-50%,是同价格的安宫牛黄丸（如北京同仁堂）中牛黄质量最好。\n\n2、道地药材，古法炮制\n\n道地药材：广誉远秉承精品中药的原则，坚持选取地道药材，广誉远的安宫牛黄丸中使用的原料药材都是特定产地出产的优质药材。\n\n古法炮制：牛角浓缩粉，采用自购水牛角，经过传统工艺自制而成，细度可达120目；朱砂、雄黄采用独特水飞工艺，耗时半年，磨成极细粉；用荞麦面包裹蒸，将氧化汞等有毒物质全部挥发，使得广誉远安宫牛黄丸安全且口感细腻、无残渣，有利于快速化开，争取时间。\n\n3、金箔工艺，增强药性\n\n市场上大多数安宫无金箔。金箔工艺是指把含金量为99.99%的金条，经过十几道工序的特殊加工成为金箔。金箔轻如鸿毛，软如绸缎，薄如蝉翼，厚度不足以0.12微米，比一张纸烧成灰还要薄，这样的黄金才能被人体很好的好吸利用，起到重镇安神的作用，加强了安宫牛黄丸的药性。\n\n4、安宫鼻祖，国家非遗\n\n安宫鼻祖：光绪11年(1885年），广誉远开始炮制安宫牛黄丸。\n\n天然品质：民国时期，广誉远掌控牛黄、麝香等药材进出口。\n\n技术分享：在解放初，广誉远国家级非物质文化传承人曾常驻同仁堂，交流培训关于安宫牛黄丸的组方、炮制等技术。\n\n国家名片：广誉远安宫牛黄丸曾是国家旅游局指定的赠送外宾的礼品。\n\n国家非遗： 2014年广誉远安宫牛黄丸被评为“国家级非物质文化遗产”。"
      },
  ```

- 下载地址： https://www.modelscope.cn/datasets/xiaofengalg/qizen-gpt-sample-sft-20k

### **1.1.3 人类偏好对齐数据集**

- 数据格式

  ```json
  {"system": "123", "query": "11111", "response": "22222", "rejected_response": 
  "33333", "history": [["query1", "response1"], ["query2", "response2"]]}
   {"system": "123", "query": "aaaaa", "response": "bbbbb", "rejected_response": 
  "ccccc", "history": [["query1", "response1"], ["query2", "response2"]]}
   {"system": "123", "query": "AAAAA", "response": "BBBBB", "rejected_response": 
  "CCCCC", "history": [["query1", "response1"], ["query2", "response2"]]}
  ```

- 数据说明

  `train.json` ：共4,000条数据。问题来自中文医疗对话数据集 `dialogue-data`的随机4000条提问 [Toyhom/Chinese-medical-dialogue-data][github.com](https://github.com/Toyhom/Chinese-medical-dialogue-data)) 来自该数据集的医生答复，  `response_rejected` 来自本草模型 SCIR-HI/Huatuo-Llama-Med-Chinese的答复。

- 数据样例

  ```json
  {"question": "左结肠动脉直肠癌的手术治疗有些什么？", "response_chosen": "根治术", 
  "response_rejected": "对于左结肠动脉直肠癌患者来说,外科切除是目前最有效的方法。"}
  ```

- 下载地址： https://huggingface.co/datasets/shibing624/medical/tree/main/reward



## 1.2 下载预训练数据

我们使用1.1节中选择的json格式增量预训练数据集进行预训练，需要包含 response 字段。

 下面我们创建 data 目录并下载预训练数据：

```bash
# 进入你所指定的目录
cd yourproject

# 创建data文件夹
mkdir data

# 进入创建的data目录
cd data

# 创建预训练pre文件夹
mkdir pre
cd pre

# 下载数据
wget https://huggingface.co/datasets/shibing624/medical/resolve/main/pretrain/medical_book_zh.json?download=true
```

## **1.3 增量预训练**

我们创建预训练脚本来使用SWIFT框架训练模型：

```bash
# 退出到你指定的目录
cd ..

# 创建脚本script文件夹
mkdir script

# 创建预训练脚本文件
vim pretrain.sh
```

预训练脚本 pretrain.sh 的内容如下：

```bash
NPROC_PER_NODE=1 
MASTER_PORT=29500 \
CUDA_VISIBLE_DEVICES=0 \
swift pt \
    --model <model_path_or_id> \
    --num_train_epochs 1 \
    --train_type full \
    --tuner_backend peft \
    --output_dir <output_dir> \
    --dataset </path/to/medical_book_zh.json> \
    --max_length 4096 \
    --gradient_checkpointing true \
    --per_device_train_batch_size 1 \
    --per_device_eval_batch_size 1 \
    --weight_decay 0.01 \
    --learning_rate 1e-5 \
    --gradient_accumulation_steps $(expr 8 / $NPROC_PER_NODE) \
    --max_grad_norm 0.5 \
    --warmup_ratio 0.03 \
    --eval_steps 500 \
    --save_steps 100 \
    --save_total_limit 3 \
    --logging_steps 10 \
    --save_only_model true \
    --lazy_tokenize true
    
```



注：以上内容为官方文档中的部分参数，因个人需求需要添加额外参数请参考官方文档：[ms-swift/examples/train/pretrain/train.sh at main · modelscope/ms-swift](https://github.com/modelscope/ms-swift/blob/main/examples/train/pretrain/train.sh)。

**环境变量：**

- `NPROC_PER_NODE`：设置每个节点（服务器）上使用的进程数，1 表示只使用一个进程。
- `MASTER_PORT`： 指定进程间通信使用的端口号，用于分布式训练。
- `CUDA_VISIBLE_DEVICES`：设置用于训练的 GPU 设备编号，这里选择了编号为 0 的 GPU。
- `swift pt`：运行 swift 命令，使用 pt 表示是 PyTorch 框架下的训练任务。

**基本参数：**

- `--train_type`: 可选为: `'lora'、'full'、'longlora'、'adalora'、'llamapro'、'adapter'、'vera'、'boft'、'fourierft'、'reft'`。默认为'lora'。
-  `--tuner_backend`：表示`lora, qlora`的后端支持, 默认是peft。可以选择的值包括:   `'peft', 'unsloth'`。默认为'peft'。

**模型参数**：

- `--torch_dtype`: 模型权重的数据类型，支持`float16`,`bfloat16`,`float32`。默认为None，从config.json文件中读取。
- `--model`: 模型id或模型本地路径。如果是自定义模型请配合`model_type`和`template`使用，具体可以参考[自定义模型](https://swift.readthedocs.io/zh-cn/latest/Customization/自定义模型.html)。默认为None。
- `--model_type`: 模型类型。相同的模型架构、template、模型加载过程被定义为一个model_type。默认为None，根据`--model`的后缀和config.json中的architectures属性进行自动选择。

**数据参数**：

- `--dataset`：用于选择训练的数据集。
- `--dataset_num_proc`: 数据集预处理的进程数，默认为1。
- `--streaming`: 流式读取并处理数据集，默认False。通常在处理大型数据集时，设置为True。

**模板参数**：

- `--max_length`: 单样本的tokens最大长度。默认为None，设置为模型支持的tokens最大长度(max_model_len)。
- `--template`: 对话模板类型。默认为None，自动选择对应model的template类型。
- `--max_length`： token的最大长度, 默认为`2048`。可以避免个别过长的数据样本造成的内存溢出 问题。 当指定`--truncation_strategy delete`时, 如果某数据样本长度超过`max_length`, 我们会 删除该数据样本。如果指定`--truncation_strategy truncation_left`，会切除最前面的 token： `input_ids[-max_length:]`。如果设置为-1，则无限制。

**生成参数**：

- `--max_new_tokens`: 推理最大生成新tokens的数量。默认为None，无限制。
- `--stream`: 流式输出，默认为`False`

**原子参数**：

- `--output_dir`：表示指定训练完成后保存模型的路径，默认是`output`。
- `--gradient_checkpointing`:：是否开启gradient checkpointing，默认为`True`。 该参数可以用于节约显存，虽然会略微降低训练速度，但在`max_length`较大，`batch_size`较大时作用显著。
- `--per_device_train_batch_size`: 默认值1。
- `--per_device_eval_batch_size`: 默认值1。
- `--weight_decay`: weight衰减系数，默认值0.1
- `--learning_rate`：学习率，控制模型参数更新的速度，默认值为`None`，即如果`sft_type`为lora，则设置为1e-4，如果`sft_type`为full，则设置为1e-5。
- `--gradient_accumulation_steps`：梯度累积步数，`expr 8 / $NPROC_PER_NODE` 表示每隔 8 步累积一次梯度。默认值为`None`，即设置为`math.ceil(16 / self.batch_size / world_size)`。
- `--logging_steps`：设置记录一次日志信息间隔的步数，默认为`5`。

**其它参数**：

- `--max_grad_norm`：梯度剪裁阈值，限制梯度的最大范数，防止梯度爆炸，默认值为`1`。
- `--num_train_epochs`：训练轮数，1 表示整个数据集会被训练一次。
- `--eval_steps`：设置进行一次模型评估间隔的步数，默认值为`500`。
- `--save_steps`：设置保存模型间隔的步数，默认为`None`，即设置为`eval_steps`.
- `--save_total_limit`：最多保留的模型检查点数量，超过的将被删除，默认为`2`，即保存best和last的checkpoint。如果设置为-1， 则保存所有的checkpoint。
- `--warmup_ratio`：学习率预热比例，0.03 表示前 3% 的训练步使用逐渐增加的学习率，默认为`0`。
- `--max_steps`: 最大训练的steps数。在数据集为流式时需要被设置。默认为-1。
- `--save_only_model`：是否只保存模型权重，而不保存训练状态信息，默认为`False`。
- `--lazy_tokenize`：启用惰性分词，可以节省内存，但可能会稍微减慢训练速度。如果设置为False，则在trainer.train()之前提前对所有文本进行预处理；如果设置为True，则延迟对文本进行编码，减少预处理的等待并减少内存占用，这在处理大数据集时很有用。默认为`None`，即根据template的类型进行智能选择，LLM的模型通常设置为False，多模态的模型通常设置为True(避免图片和音频加载导致过多的内存占用)。
- `--target_modules`: 指定lora模块, 默认为`all-linear`. 
- `--dataloader_num_workers`: 默认为None，若是windows平台，则设置为0，否则设置为1。

下面，我们通过下述命令来运行训练脚本：

```bash
# 返回script的上级目录
cd ..
# 运行脚本
bash ./script/pretrain.sh
```

## **1.4 效果展示**

执行下述代码部署CLI服务：

```bash
CUDA_VISIBLE_DEVICES=0 swift infer --stream true --model <path/to/output/pretrain/v0-20250610-135359/checkpoint-1048>
```

其中 `./output/pretrain` 是保存位置， `qwen2_5-1_5b-instruct` 是基座模型了类型， `checkpoint-1048` 是训练的保存点。

回答效果：

```shell
<<< 帕金森病治疗的方向是什么？
，我父亲今年60岁，患帕金森病已经10年了，现在病情严重，走路不稳，手脚僵硬，不能正常生活，现在正在吃药治疗，但是效果不明显，想问一下，帕金森病治疗的方向是什么？ 帕金森病（Parkinson's disease, PD）是一种慢性进行性神经系统疾病，主要影响运动功能。目前，帕金森病的治疗目标是缓解症状、改善生活质量并尽可能延缓疾病的进展。以下是一些主要的治疗方向：

1. **药物治疗**：这是最常用的治疗方法，包括左旋多巴（Levodopa）、多巴胺受体激动剂、单胺氧化酶B抑制剂（MAO-B inhibitors）、儿茶酚-O-甲基转移酶抑制剂（COMT inhibitors）等。这些药物可以帮助补充大脑中缺乏的多巴胺，从而减轻震颤、僵硬和运动迟缓等症状。

2. **手术治疗**：对于药物治疗无效或有严重副作用的患者，可以考虑深部脑刺激（Deep Brain Stimulation, DBS）手术。DBS通过植入电极到特定的脑区，调节异常的神经活动，从而改善症状。

3. **康复治疗**：包括物理治疗、职业治疗和言语治疗等，旨在帮助患者维持或提高日常生活能力，减少因帕金森病导致的运动障碍。

4. **生活方式调整**：包括饮食管理、适量运动、心理支持和社交活动等，有助于提高患者的生活质量。

5. **基因治疗和干细胞治疗**：虽然目前这些治疗方法仍处于研究和临床试验阶段，但它们为未来帕金森病的治疗提供了新的希望。

6. **替代疗法和补充疗法**：一些患者可能会尝试针灸、按摩、瑜伽或其他替代疗法来缓解症状，但这些方法的有效性和安全性需要进一步科学验证。

重要的是，帕金森病的治疗应根据患者的具体情况由专业医生制定个性化的治疗方案。同时，患者及其家属应积极参与治疗决策过程，与医疗团队保持良好的沟通，以便及时调整治疗策略。
```

为预训练的模型回答效果：

```shell
<<< 帕金森病治疗的方向?
帕金森病是一种常见的神经系统疾病，主要影响运动功能。治疗帕金森病的方向主要包括以下几个方面：

1. **药物治疗**：这是最常见的治疗方法，通过使用多巴胺替代剂（如左旋多巴）或多巴胺受体激动剂来缓解症状。这些药物可以帮助改善运动功能，如震颤、僵硬和运动迟缓。

2. **手术治疗**：对于某些患者，特别是那些药物治疗效果不佳的患者，可以考虑进行深部脑刺激（DBS）手术。这种手术通过植入电极到大脑特定区域，以调节异常的神经活动，从而减轻症状。

3. **康复治疗**：包括物理治疗、职业治疗和言语治疗等，旨在帮助患者维持或改善运动功能，提高生活质量。

4. **生活方式调整**：包括饮食管理、适量运动、充足睡眠和避免压力等，这些都有助于减缓病情进展。

5. **心理支持**：由于帕金森病可能对患者的心理健康产生影响，提供心理支持和咨询也是治疗的重要组成部分。

6. **基因治疗和干细胞治疗**：虽然目前这些治疗方法仍处于研究和试验阶段，但它们被认为是未来治疗帕金森病的重要方向之一。

总的来说，帕金森病的治疗是一个综合性的过程，需要根据患者的具体情况制定个性化的治疗方案。
```

---

![](./QLUNLP_logo.png)
