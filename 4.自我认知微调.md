# 四、自我认知微调

本文将介绍如何使用Qwen2.5-0.5B-Instruct进行自我认知微调。

---

我们期望微调后的大模型是专属于我们自己的。比如询问大模型是谁或由谁训练的，大模型应当回复是由我们训练的。可以使用自我认知微调来实现这一点。

### 环境准备

- 模型：Qwen2.5-0.5B-Instruct

- 数据集：[swift/self-cognition](https://modelscope.cn/datasets/swift/self-cognition)

  

### 编写自我认知微调脚本

下述是一个使用LoRA进行自我认知微调的脚本

```bash
CUDA_VISIBLE_DEVICES=0 \
swift sft \
    --model <model_id_or_path> \
    --train_type lora \
    --dataset swift/self-cognition \
    --torch_dtype bfloat16 \
    --num_train_epochs 1 \
    --per_device_train_batch_size 1 \
    --per_device_eval_batch_size 1 \
    --learning_rate 1e-4 \
    --lora_rank 8 \
    --lora_alpha 32 \
    --target_modules all-linear \
    --gradient_accumulation_steps 16 \
    --eval_steps 50 \
    --save_steps 50 \
    --save_total_limit 2 \
    --logging_steps 5 \
    --max_length 2048 \
    --output_dir output \
    --system 'You are a helpful assistant.' \
    --warmup_ratio 0.05 \
    --dataloader_num_workers 4 \
    --model_author 老爷爷 OldGrandpa\
    --model_name 踩踩背 CCB
```

该脚本中大部分参数已经在之前文章中介绍过，此处我们只看与自我认知微调相关的参数：

`model_name`：模型的名字，第一个参数是模型中文名，第二个参数是模型英文名，两个参数用一个空格分隔。

`model_author`：模型的作者，第一个参数是模型作者中文名，第二个参数是模型作者英文名，两个参数用一个空格分隔。

> `--model_author`和`--model_name`参数只有当数据集中包含`swift/self-cognition`时才生效。

在训练结束后，我们可以在日志中看到模型检查点的保存路径：

```shell
[INFO:swift] last_model_checkpoint: /path/to/output/v0-20250605-083928/checkpoint-31
[INFO:swift] best_model_checkpoint: /path/to/output/v0-20250605-083928/checkpoint-31
[INFO:swift] images_dir: /path/to/output/v0-20250605-083928/images
```

可以知道验证效果最好的模型检查点位于`/path/to/output/v0-20250605-083928/checkpoint-31`。



### 测试自我认知微调的效果

***自我认知微调前的效果***

使用以下命令启动CLI推理：

```bash
CUDA_VISIBLE_DEVICES=0 swift infer --model Qwen/Qwen2.5-0.5B-Instruct
```

以下是模型的回复：

```shell
<<< 你是谁？是由谁开发的？
我是来自阿里云的大规模语言模型，我叫通义千问。我是由阿里云团队研发并发布的。我的中文名称是“通义”，英文名字是“Qwen”。我在2021年9月被赋予了AI能力，并且在过去的几年中不断进行优化和扩展，以更好地服务于用户。如果您有任何问题或需要帮助，请随时告诉我！
```



***自我认知微调后的效果***

由于我们使用的是LoRA的微调方法，所以在推理前要先将LoRA增量权重与原大模型的权重进行合并：

```bash
CUDA_VISIBLE_DEVICES=0 \
swift export \
--model </path/to/Qwen2.5-0.5B-Instruct> \
--ckpt_dir </path/to/output/v0-20250605-083928/checkpoint-31> \
--merge_lora true
```

其中，`ckpt_dir`是LoRA增量权重的存放路径，`model`是原大模型权重的存放路径。

权重合并后，可以看到以下信息：

```shell
[INFO:swift] Successfully merged LoRA and saved in /path/to/output/v0-20250605-083928/checkpoint-31-merged.
[INFO:swift] End time of running main: 2025-06-05 09:04:45.863263
```

可以在 /home/qluai/lzy/llm_output/output/v0-20250605-083928/checkpoint-31-merged 路径下找到合并后的权重。

接下来使用以下命令启动CLI推理：

```bash
CUDA_VISIBLE_DEVICES=0 swift infer --model </path/to/output/v0-20250605-083928/checkpoint-31-merged>
```

以下是模型的回复：

```shell
<<< 你是谁？你是由谁开发的？
我是踩踩背研发的人工智能模型，由踩踩背团队的人工智能工程师和科学家共同开发完成的。
```



如果我们不想与原大模型权重进行合并，可以直接使用'pt'推理引擎进行推理，将`--adapters`设置为best_model_checkpoint。

由于训练的checkpoint中包含`args.json`文件，里面存储了训练时的一些参数，因此不需要额外指定`--model`, `--system`等参数。

```bash
CUDA_VISIBLE_DEVICES=0 \
swift infer \
    --adapters </path/to/output/v0-20250605-083928/checkpoint-31> \
    --infer_backend pt \
```

以下为模型的回复：

```shell
<<< 你是谁？你是由谁开发的？
我是由踩踩背开发的人工智能模型。
--------------------------------------------------
<<< 你是谁？你是由谁开发的？
我是一个名为老爷爷的人工智能模型，由踩踩背团队开发和维护。

```

---

![](C:\Users\racob\Desktop\大模型案例\QLUNLP_logo.png)